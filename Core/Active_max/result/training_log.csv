Epoch,Step,Training Loss,Validation Loss
1,1,33.101147,
1,2,22.300833,
1,3,32.90494,
1,4,28.9572,
1,5,19.8221,
1,6,30.441916,
1,7,32.091396,
1,8,31.73437,
1,9,30.361383,
1,10,26.290754,
1,11,32.742188,
1,12,27.367533,
1,13,32.500965,
1,14,31.591898,
1,15,32.305588,
1,16,28.215929,
1,17,27.810196,
1,18,31.599316,
1,19,31.71017,
1,20,30.869596,
1,21,30.438007,
1,22,28.662188,
1,23,31.161793,
1,24,27.608559,
1,25,31.347902,
1,26,27.78862,
1,27,28.753855,
1,28,30.438719,
1,29,29.558628,
1,30,27.960432,
1,31,27.353207,
1,32,27.493195,
1,33,28.401125,
1,34,29.58129,
1,35,27.378094,
1,36,26.745083,
1,37,23.361544,
1,38,25.589014,
1,39,27.116266,
1,40,28.207682,
1,41,27.374765,
1,42,25.995478,
1,43,17.869457,
1,44,26.790373,
1,45,25.395927,
1,46,25.336456,
1,47,24.840479,
1,48,24.293898,
1,49,24.813017,
1,50,24.018808,
1,51,22.040222,
1,52,20.472496,
1,53,12.978534,
1,54,21.128624,
1,55,20.57179,
1,56,20.177788,
1,57,18.271921,
1,58,19.547234,
1,59,16.394884,
1,60,17.306929,
1,61,18.808973,
1,62,17.51388,
1,63,17.515944,
1,64,16.904003,
1,65,14.708622,
1,66,15.2135,
1,67,5.290284,
1,68,11.29541,
1,69,13.946688,
1,70,11.985658,
1,71,10.367829,
1,72,10.013562,
1,73,9.037693,
1,74,8.606385,
1,75,5.2354593,
1,76,4.2841635,
1,77,4.8117986,
1,78,3.0373125,
1,79,0.9966869,
1,80,2.0566552,
1,81,6.293761,
1,82,7.324165,
1,83,-2.7339277,
1,84,-0.99987924,
1,85,-0.58746046,
1,86,-3.325416,
1,87,-2.80343,
1,88,-7.546708,
1,89,-6.7885847,
1,90,-6.9755297,
1,91,-8.652428,
1,92,-10.814506,
1,93,-13.492192,
1,94,-10.421719,
1,95,-10.106852,
1,96,-12.400397,
1,97,-17.62361,
1,98,87.84827,
1,99,235.51476,
1,100,46.785545,
1,100,,-17.880339845127555
